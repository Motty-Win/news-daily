import streamlit as st
import yaml, time
from utils.rss import fetch_feed
from utils.llm import summarize_item
from utils.nlp import cluster_by_title

# ã‚¢ãƒ—ãƒªåŸºæœ¬æƒ…å ±
st.set_page_config(page_title="Daily News Summarizer", layout="wide")
st.title("ğŸ“° ä¸€æ—¥ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¾ã¨ã‚")

# RSSãƒ•ã‚£ãƒ¼ãƒ‰èª­ã¿è¾¼ã¿
# ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’è¿½åŠ 
try:
    with open("feeds.yaml", "r") as f:
        feeds = yaml.safe_load(f)
except FileNotFoundError:
    st.error("feeds.yaml ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    st.stop()
except yaml.YAMLError as e:
    st.error(f"feeds.yaml ã®è§£æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    st.stop()

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼ˆè¨­å®šï¼‰
with st.sidebar:
    st.header("è¨­å®š")
    category_limits = {}
    for feed in feeds:
        category_limits[feed["name"]] = st.number_input(
            f"{feed['name']}ã®æœ€å¤§è¨˜äº‹æ•°", min_value=1, max_value=15, value=3, step=1
        )
    do_cluster = st.checkbox("é¡ä¼¼è¨˜äº‹ã‚’ã¾ã¨ã‚ã‚‹", value=True)
    threshold = 0.6  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®š
    st.caption("â€»è¦ç´„ã¯APIã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")

    # ã‚¹ã‚¿ãƒ¼ãƒˆãƒœã‚¿ãƒ³
    start_button = st.button("ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—")

# ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—å‡¦ç†ã‚’ã‚¹ã‚¿ãƒ¼ãƒˆãƒœã‚¿ãƒ³ã«é€£å‹•
if start_button:
    rows = []
    for feed in feeds:
        items = fetch_feed(feed["url"])[: category_limits[feed["name"]]]
        for it in items:
            it["category"] = feed["name"]
        rows.extend(items)

    # æ—¥ä»˜é †ã§ä¸¦ã¹æ›¿ãˆï¼ˆæ–°ã—ã„é †ï¼‰
    rows = sorted(rows, key=lambda x: x["published_ts"], reverse=True)

    # ãƒ•ã‚£ãƒ¼ãƒ‰ãŒç©ºã®å ´åˆ
    if not rows:
        st.info("ãƒ•ã‚£ãƒ¼ãƒ‰ãŒç©ºã§ã—ãŸã€‚feeds.yamlã‚’è¦‹ç›´ã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    # é¡ä¼¼è¨˜äº‹ã¾ã¨ã‚ï¼ˆã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ï¼‰
    clusters = (
        cluster_by_title(rows, n_clusters=None, distance_threshold=threshold)
        if do_cluster
        else [[i] for i in range(len(rows))]
    )

    md_out = ["# ä»Šæ—¥ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¾ã¨ã‚\n"]

    # å„ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã«è¦ç´„
    for ci, cluster in enumerate(clusters, start=1):
        section_items = [rows[i] for i in cluster]
        head = section_items[0]["title"] if section_items else f"ãƒˆãƒ”ãƒƒã‚¯ {ci}"
        st.subheader(f"{ci}. {head}")

        merged_text = "\n\n".join(
            f"- {it['title']}ï¼ˆ{it['source']}ï¼‰\n{it['summary']}\n{it['link']}\nï¼ˆã‚«ãƒ†ã‚´ãƒª: {it['category']}ï¼‰"
            for it in section_items
        )

        with st.spinner("ğŸ§  è¦ç´„ä¸­..."):
            try:
                s = summarize_item(merged_text)  # ä¿®æ­£: summarize_itemã«1ã¤ã®å¼•æ•°ã‚’æ¸¡ã™
            except Exception as e:
                s = f"è¦ç´„ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}"

        st.markdown(f"{s}\n\nï¼ˆã‚«ãƒ†ã‚´ãƒª: {section_items[0]['category']}ï¼‰")
        md_out.append(s)
        with st.expander("ğŸ” é–¢é€£è¨˜äº‹ä¸€è¦§"):
            for it in section_items:
                st.markdown(
                    f"- **[{it['title']}]({it['link']})**  Â· {it['source']} Â· "
                    f"{time.strftime('%Y-%m-%d %H:%M', time.localtime(it['published_ts']))} Â· ã‚«ãƒ†ã‚´ãƒª: {it['category']}"
                )

    # Markdownã¨ã—ã¦å‡ºåŠ›ä¿å­˜
    md_all = "\n\n".join(md_out)
    st.download_button(
        "ğŸ“¥ Markdownã¨ã—ã¦ä¿å­˜", md_all, file_name="daily_news.md", mime="text/markdown"
    )
    st.success("âœ… ã‚¢ãƒ—ãƒªã®æº–å‚™ãŒå®Œäº†ã—ã¾ã—ãŸï¼Streamlitã‚’èµ·å‹•ã—ã¦ç¢ºèªã—ã¾ã—ã‚‡ã†ğŸš€")
